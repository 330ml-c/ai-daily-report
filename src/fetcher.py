"""
GitHub AI é¡¹ç›®æ•°æ®æŠ“å–æ¨¡å—
è´Ÿè´£ä» GitHub API è·å–æ´»è·ƒçš„ AI ç›¸å…³é¡¹ç›®
"""

import os
from datetime import datetime, timedelta
from typing import List, Dict, Any
import requests


class GitHubFetcher:
    """GitHub é¡¹ç›®æ•°æ®æŠ“å–å™¨"""

    # AI ç›¸å…³çš„æœç´¢å…³é”®è¯
    SEARCH_TOPICS = [
        "llm",
        "mcp",
        "langchain",
        "agent",
        "openai",
        "anthropic",
        "machine-learning",
        "deep-learning",
    ]

    def __init__(self, github_token: str):
        """
        åˆå§‹åŒ– GitHub API å®¢æˆ·ç«¯

        Args:
            github_token: GitHub Personal Access Token
        """
        self.token = github_token
        self.base_url = "https://api.github.com"
        self.headers = {
            "Authorization": f"Bearer {github_token}",
            "Accept": "application/vnd.github+json"
        }

    def _search_repositories(self, query: str, per_page: int = 20) -> List[Dict]:
        """
        æœç´¢ä»“åº“

        Args:
            query: æœç´¢æŸ¥è¯¢
            per_page: æ¯é¡µç»“æœæ•°é‡

        Returns:
            ä»“åº“åˆ—è¡¨
        """
        response = requests.get(
            f"{self.base_url}/search/repositories",
            params={
                "q": query,
                "sort": "updated",
                "order": "desc",
                "per_page": per_page
            },
            headers=self.headers
        )

        if response.status_code == 200:
            data = response.json()
            return data.get("items", [])
        else:
            print(f"  âŒ æœç´¢å¤±è´¥: {response.status_code} - {response.text[:100]}")
            return []

    def _calculate_activity_score(self, repo_data: Dict) -> float:
        """
        è®¡ç®—ä»“åº“æ´»è·ƒåº¦åˆ†æ•°

        ç»¼åˆè€ƒè™‘ï¼š
        - Star æ•° (æƒé‡ 0.3)
        - Fork æ•° (æƒé‡ 0.2)
        - æœ€è¿‘æ›´æ–°æ—¶é—´ (æƒé‡ 0.3)
        - Open Issues æ•°é‡ (æƒé‡ 0.2)

        Args:
            repo_data: ä»“åº“æ•°æ®å­—å…¸

        Returns:
            æ´»è·ƒåº¦åˆ†æ•° (è¶Šé«˜è¶Šæ´»è·ƒ)
        """
        stars = repo_data.get("stargazers_count", 0)
        forks = repo_data.get("forks_count", 0)
        open_issues = repo_data.get("open_issues_count", 0)

        # æœ€è¿‘æ›´æ–°æ—¶é—´åˆ†æ•°
        updated_at_str = repo_data.get("updated_at", "")
        try:
            updated_at = datetime.fromisoformat(updated_at_str.replace("Z", "+00:00"))
            days_since_update = (datetime.now(updated_at.tzinfo) - updated_at).days
            recency_score = max(0, 100 - days_since_update)
        except:
            recency_score = 50  # é»˜è®¤åˆ†æ•°

        # ç»¼åˆè®¡ç®—
        activity_score = (
            stars * 0.3 +
            forks * 0.2 +
            recency_score * 10 +
            open_issues * 0.2
        )

        return activity_score

    def _extract_repo_info(self, repo_data: Dict) -> Dict[str, Any]:
        """
        æå–ä»“åº“ä¿¡æ¯

        Args:
            repo_data: GitHub API è¿”å›çš„ä»“åº“æ•°æ®

        Returns:
            ä»“åº“ä¿¡æ¯å­—å…¸
        """
        return {
            "name": repo_data["full_name"],
            "description": repo_data.get("description") or "æš‚æ— æè¿°",
            "url": repo_data["html_url"],
            "stars": repo_data.get("stargazers_count", 0),
            "forks": repo_data.get("forks_count", 0),
            "open_issues": repo_data.get("open_issues_count", 0),
            "language": repo_data.get("language") or "Unknown",
            "created_at": repo_data.get("created_at", ""),
            "updated_at": repo_data.get("updated_at", ""),
            "topics": repo_data.get("topics", []),
        }

    def fetch_active_ai_projects(self, limit: int = 30) -> List[Dict[str, Any]]:
        """
        è·å–æ´»è·ƒçš„ AI é¡¹ç›®

        Args:
            limit: è·å–çš„é¡¹ç›®æ•°é‡

        Returns:
            é¡¹ç›®ä¿¡æ¯åˆ—è¡¨ï¼ŒæŒ‰æ´»è·ƒåº¦æ’åº
        """
        all_projects = {}

        # åˆ†åˆ«æœç´¢æ¯ä¸ªä¸»é¢˜ï¼Œç„¶ååˆå¹¶å»é‡
        for topic in self.SEARCH_TOPICS[:4]:  # åªæœç´¢å‰4ä¸ªä¸»é¢˜ä»¥èŠ‚çœ API é…é¢
            query = f"topic:{topic}"

            print(f"ğŸ” æœç´¢ä¸»é¢˜: {topic}")

            repos = self._search_repositories(query, per_page=20)
            print(f"  ğŸ“¦ è·å–åˆ° {len(repos)} ä¸ªä»“åº“")

            for repo_data in repos:
                # ä½¿ç”¨é¡¹ç›®åç§°ä½œä¸ºå”¯ä¸€æ ‡è¯†å»é‡
                repo_name = repo_data["full_name"]
                if repo_name not in all_projects:
                    info = self._extract_repo_info(repo_data)
                    info["activity_score"] = self._calculate_activity_score(repo_data)
                    all_projects[repo_name] = info
                    print(f"  âœ“ è·å–: {info['name']} (â­ {info['stars']})")

        # è½¬æ¢ä¸ºåˆ—è¡¨å¹¶æŒ‰æ´»è·ƒåº¦æ’åº
        projects = list(all_projects.values())
        projects.sort(key=lambda x: x["activity_score"], reverse=True)

        return projects[:limit]

    def get_readme_content(self, repo_name: str) -> str:
        """
        è·å–ä»“åº“çš„ README å†…å®¹

        Args:
            repo_name: ä»“åº“å…¨å (owner/repo)

        Returns:
            README å†…å®¹ (Markdown æ ¼å¼)
        """
        try:
            # å…ˆå°è¯•è·å– README æ–‡ä»¶
            response = requests.get(
                f"{self.base_url}/repos/{repo_name}/readme",
                headers=self.headers
            )

            if response.status_code == 200:
                data = response.json()
                # README å†…å®¹æ˜¯ base64 ç¼–ç çš„
                import base64
                content = base64.b64decode(data["content"]).decode("utf-8")
                return content
            else:
                return ""
        except Exception as e:
            print(f"  âš ï¸  è·å– README å¤±è´¥ {repo_name}: {e}")
            return ""
